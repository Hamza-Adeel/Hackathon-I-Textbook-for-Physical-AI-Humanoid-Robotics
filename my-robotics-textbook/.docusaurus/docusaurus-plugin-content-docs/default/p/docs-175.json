{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"roboticsTextbookSidebar":[{"type":"category","label":"Chapter 1: The Robotic Nervous System (ROS 2)","items":[{"type":"link","href":"/docs/ros-2/understanding-nodes-topics-services","label":"Understanding ROS 2 Nodes, Topics, & Services","docId":"ros-2/understanding-nodes-topics-services","unlisted":false},{"type":"link","href":"/docs/ros-2/python-rclpy","label":"Building ROS 2 Systems with Python (rclpy)","docId":"ros-2/python-rclpy","unlisted":false},{"type":"link","href":"/docs/ros-2/urdf-for-humanoids","label":"Describing Robots with URDF","docId":"ros-2/urdf-for-humanoids","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/docs/ros-2"},{"type":"category","label":"Chapter 2: The Digital Twin (Gazebo & Unity)","items":[{"type":"link","href":"/docs/digital-twin/physics-simulation","label":"Fundamentals of Physics Simulation (Gravity, Collisions)","docId":"digital-twin/physics-simulation","unlisted":false},{"type":"link","href":"/docs/digital-twin/setup-environments","label":"Setting up Environments in Gazebo and Unity","docId":"digital-twin/setup-environments","unlisted":false},{"type":"link","href":"/docs/digital-twin/simulating-sensors","label":"Simulating Sensors (LiDAR, Depth Cameras, IMUs)","docId":"digital-twin/simulating-sensors","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/docs/digital-twin"},{"type":"category","label":"Chapter 3: The AI-Robot Brain (NVIDIA Isaac)","items":[{"type":"link","href":"/docs/nvidia-isaac/intro-to-isaac-sim","label":"Introduction to Isaac Sim for Photorealistic Simulation","docId":"nvidia-isaac/intro-to-isaac-sim","unlisted":false},{"type":"link","href":"/docs/nvidia-isaac/synthetic-data","label":"Generating Synthetic Datasets","docId":"nvidia-isaac/synthetic-data","unlisted":false},{"type":"link","href":"/docs/nvidia-isaac/isaac-ros-vslam","label":"Implementing Isaac ROS VSLAM & Navigation","docId":"nvidia-isaac/isaac-ros-vslam","unlisted":false},{"type":"link","href":"/docs/nvidia-isaac/nav2-path-planning","label":"Advanced Path Planning with Nav2 for Humanoids","docId":"nvidia-isaac/nav2-path-planning","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/docs/nvidia-isaac"},{"type":"category","label":"Chapter 4: Vision-Language-Action (VLA)","items":[{"type":"link","href":"/docs/vla/whisper-voice-commands","label":"Converting Speech to Text with Whisper","docId":"vla/whisper-voice-commands","unlisted":false},{"type":"link","href":"/docs/vla/llm-cognitive-planning","label":"LLM-Based Cognitive Planning","docId":"vla/llm-cognitive-planning","unlisted":false},{"type":"link","href":"/docs/vla/capstone-project","label":"Capstone Project: Building an Autonomous Humanoid Assistant","docId":"vla/capstone-project","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/docs/vla"}]},"docs":{"digital-twin/physics-simulation":{"id":"digital-twin/physics-simulation","title":"Fundamentals of Physics Simulation (Gravity, Collisions)","description":"This lesson explores the core principles behind physics simulation in robotics, focusing on gravity and collision detection.","sidebar":"roboticsTextbookSidebar"},"digital-twin/setup-environments":{"id":"digital-twin/setup-environments","title":"Setting up Environments in Gazebo and Unity","description":"This lesson guides you through setting up simulation environments in Gazebo and Unity for digital twin development.","sidebar":"roboticsTextbookSidebar"},"digital-twin/simulating-sensors":{"id":"digital-twin/simulating-sensors","title":"Simulating Sensors (LiDAR, Depth Cameras, IMUs)","description":"This lesson delves into simulating various robotic sensors within digital twin environments, focusing on LiDAR, depth cameras, and IMUs.","sidebar":"roboticsTextbookSidebar"},"nvidia-isaac/intro-to-isaac-sim":{"id":"nvidia-isaac/intro-to-isaac-sim","title":"Introduction to Isaac Sim for Photorealistic Simulation","description":"This lesson introduces NVIDIA Isaac Sim, a powerful platform for photorealistic simulation and robotics development.","sidebar":"roboticsTextbookSidebar"},"nvidia-isaac/isaac-ros-vslam":{"id":"nvidia-isaac/isaac-ros-vslam","title":"Implementing Isaac ROS VSLAM & Navigation","description":"This lesson covers implementing Visual SLAM (VSLAM) and navigation capabilities using NVIDIA Isaac ROS modules within Isaac Sim.","sidebar":"roboticsTextbookSidebar"},"nvidia-isaac/nav2-path-planning":{"id":"nvidia-isaac/nav2-path-planning","title":"Advanced Path Planning with Nav2 for Humanoids","description":"This lesson builds upon basic navigation and explores advanced path planning concepts within Nav2, specifically tailored for humanoid robots.","sidebar":"roboticsTextbookSidebar"},"nvidia-isaac/synthetic-data":{"id":"nvidia-isaac/synthetic-data","title":"Generating Synthetic Datasets","description":"This lesson explores the process and benefits of generating synthetic datasets using NVIDIA Isaac Sim for training AI models.","sidebar":"roboticsTextbookSidebar"},"ros-2/python-rclpy":{"id":"ros-2/python-rclpy","title":"Building ROS 2 Systems with Python (rclpy)","description":"This lesson focuses on practical application of ROS 2 concepts using rclpy, the Python client library for ROS 2.","sidebar":"roboticsTextbookSidebar"},"ros-2/understanding-nodes-topics-services":{"id":"ros-2/understanding-nodes-topics-services","title":"Understanding ROS 2 Nodes, Topics, & Services","description":"This lesson will cover the fundamental concepts of ROS 2 communication: Nodes, Topics, and Services.","sidebar":"roboticsTextbookSidebar"},"ros-2/urdf-for-humanoids":{"id":"ros-2/urdf-for-humanoids","title":"Describing Robots with URDF","description":"This lesson introduces the Unified Robot Description Format (URDF) for modeling robots in ROS 2.","sidebar":"roboticsTextbookSidebar"},"vla/capstone-project":{"id":"vla/capstone-project","title":"Capstone Project: Building an Autonomous Humanoid Assistant","description":"This capstone project integrates all concepts learned throughout the textbook to build a basic autonomous humanoid assistant capable of understanding and executing high-level commands.","sidebar":"roboticsTextbookSidebar"},"vla/llm-cognitive-planning":{"id":"vla/llm-cognitive-planning","title":"LLM-Based Cognitive Planning","description":"This lesson explores how Large Language Models (LLMs) can be leveraged for high-level cognitive planning in robotics, translating abstract human commands into executable robot actions.","sidebar":"roboticsTextbookSidebar"},"vla/whisper-voice-commands":{"id":"vla/whisper-voice-commands","title":"Converting Speech to Text with Whisper","description":"This lesson introduces OpenAI's Whisper model for highly accurate speech-to-text conversion, enabling natural language understanding for robotic commands.","sidebar":"roboticsTextbookSidebar"}}}}
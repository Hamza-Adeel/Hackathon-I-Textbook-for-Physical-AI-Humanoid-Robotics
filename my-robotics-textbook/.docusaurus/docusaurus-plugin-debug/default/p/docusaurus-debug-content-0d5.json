{"allContent":{"docusaurus-plugin-css-cascade-layers":{},"docusaurus-plugin-content-docs":{"default":{"loadedVersions":[{"versionName":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","path":"/docs","tagsPath":"/docs/tags","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs","isLast":true,"routePriority":-1,"sidebarFilePath":"D:\\Agentic-AI-SDK\\hackathon\\my-robotics-textbook\\sidebars.ts","contentPath":"D:\\Agentic-AI-SDK\\hackathon\\my-robotics-textbook\\docs","docs":[{"id":"digital-twin/physics-simulation","title":"The Physics of Simulation","description":"A digital twin is more than just a 3D model; it's a dynamic representation that behaves like its real-world counterpart. The magic behind this realism is the physics engine, a core component of any robotics simulator.","source":"@site/docs/digital-twin/physics-simulation.md","sourceDirName":"digital-twin","slug":"/digital-twin/physics-simulation","permalink":"/docs/digital-twin/physics-simulation","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/digital-twin/physics-simulation.md","tags":[],"version":"current","frontMatter":{"title":"The Physics of Simulation","sidebar_label":"Physics Simulation"},"sidebar":"roboticsTextbookSidebar","previous":{"title":"Setup Environments","permalink":"/docs/digital-twin/setup-environments"},"next":{"title":"Simulating Sensors","permalink":"/docs/digital-twin/simulating-sensors"}},{"id":"digital-twin/setup-environments","title":"Setting up Simulation Environments","description":"Welcome to the second chapter, where we dive into the world of Digital Twins. A digital twin is a virtual model of a physical object or system, and in robotics, simulation is our primary tool for creating and interacting with them.","source":"@site/docs/digital-twin/setup-environments.md","sourceDirName":"digital-twin","slug":"/digital-twin/setup-environments","permalink":"/docs/digital-twin/setup-environments","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/digital-twin/setup-environments.md","tags":[],"version":"current","frontMatter":{"title":"Setting up Simulation Environments","sidebar_label":"Setup Environments"},"sidebar":"roboticsTextbookSidebar","previous":{"title":"URDF for Humanoids","permalink":"/docs/ros-2/urdf-for-humanoids"},"next":{"title":"Physics Simulation","permalink":"/docs/digital-twin/physics-simulation"}},{"id":"digital-twin/simulating-sensors","title":"Simulating Complex Sensors","description":"For a digital twin to be useful, it must not only simulate the robot's motion but also the data it perceives from its environment. Modern robotics simulators provide a wide array of plugins for modeling complex sensors.","source":"@site/docs/digital-twin/simulating-sensors.md","sourceDirName":"digital-twin","slug":"/digital-twin/simulating-sensors","permalink":"/docs/digital-twin/simulating-sensors","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/digital-twin/simulating-sensors.md","tags":[],"version":"current","frontMatter":{"title":"Simulating Complex Sensors","sidebar_label":"Simulating Sensors"},"sidebar":"roboticsTextbookSidebar","previous":{"title":"Physics Simulation","permalink":"/docs/digital-twin/physics-simulation"},"next":{"title":"Intro to Isaac Sim","permalink":"/docs/nvidia-isaac/intro-to-isaac-sim"}},{"id":"nvidia-isaac/intro-to-isaac-sim","title":"Introduction to Isaac Sim","description":"Welcome to Chapter 3, where we explore NVIDIA's powerful robotics platform, Isaac Sim. While Gazebo is a fantastic general-purpose robotics simulator, Isaac Sim excels in creating high-fidelity, photorealistic worlds, making it a premier choice for developing AI-powered robots that rely on vision and perception.","source":"@site/docs/nvidia-isaac/intro-to-isaac-sim.md","sourceDirName":"nvidia-isaac","slug":"/nvidia-isaac/intro-to-isaac-sim","permalink":"/docs/nvidia-isaac/intro-to-isaac-sim","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/nvidia-isaac/intro-to-isaac-sim.md","tags":[],"version":"current","frontMatter":{"title":"Introduction to Isaac Sim","sidebar_label":"Intro to Isaac Sim"},"sidebar":"roboticsTextbookSidebar","previous":{"title":"Simulating Sensors","permalink":"/docs/digital-twin/simulating-sensors"},"next":{"title":"Synthetic Data","permalink":"/docs/nvidia-isaac/synthetic-data"}},{"id":"nvidia-isaac/isaac-ros-vslam","title":"Implementing Isaac ROS VSLAM & Navigation","description":"This lesson covers implementing Visual SLAM (VSLAM) and navigation capabilities using NVIDIA Isaac ROS modules within Isaac Sim.","source":"@site/docs/nvidia-isaac/isaac-ros-vslam.md","sourceDirName":"nvidia-isaac","slug":"/nvidia-isaac/isaac-ros-vslam","permalink":"/docs/nvidia-isaac/isaac-ros-vslam","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/nvidia-isaac/isaac-ros-vslam.md","tags":[],"version":"current","frontMatter":{}},{"id":"nvidia-isaac/nav2-path-planning","title":"Integrating Nav2 for Path Planning","description":"While Isaac Sim is a powerful tool for perception and AI training, robotics is fundamentally about moving and acting in an environment. To achieve autonomous navigation, we can integrate our Isaac Sim simulation with Nav2, the standard navigation stack in ROS 2.","source":"@site/docs/nvidia-isaac/nav2-path-planning.md","sourceDirName":"nvidia-isaac","slug":"/nvidia-isaac/nav2-path-planning","permalink":"/docs/nvidia-isaac/nav2-path-planning","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/nvidia-isaac/nav2-path-planning.md","tags":[],"version":"current","frontMatter":{"title":"Integrating Nav2 for Path Planning","sidebar_label":"Nav2 Path Planning"},"sidebar":"roboticsTextbookSidebar","previous":{"title":"Synthetic Data","permalink":"/docs/nvidia-isaac/synthetic-data"},"next":{"title":"Whisper Voice Commands","permalink":"/docs/vla/whisper-voice-commands"}},{"id":"nvidia-isaac/synthetic-data","title":"Generating Synthetic Data for Training","description":"One of the most significant bottlenecks in developing modern, AI-powered robots is the need for vast amounts of high-quality, labeled training data. Manually collecting and labeling thousands of images or sensor readings is slow, expensive, and error-prone.","source":"@site/docs/nvidia-isaac/synthetic-data.md","sourceDirName":"nvidia-isaac","slug":"/nvidia-isaac/synthetic-data","permalink":"/docs/nvidia-isaac/synthetic-data","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/nvidia-isaac/synthetic-data.md","tags":[],"version":"current","frontMatter":{"title":"Generating Synthetic Data for Training","sidebar_label":"Synthetic Data"},"sidebar":"roboticsTextbookSidebar","previous":{"title":"Intro to Isaac Sim","permalink":"/docs/nvidia-isaac/intro-to-isaac-sim"},"next":{"title":"Nav2 Path Planning","permalink":"/docs/nvidia-isaac/nav2-path-planning"}},{"id":"ros-2/python-rclpy","title":"Writing a Python ROS 2 Node (RCLPy)","description":"In our previous lesson, we learned about the theoretical concepts of nodes, topics, and services. Now, it's time to put that theory into practice by writing our first ROS 2 node using rclpy, the official Python client library for ROS 2.","source":"@site/docs/ros-2/python-rclpy.md","sourceDirName":"ros-2","slug":"/ros-2/python-rclpy","permalink":"/docs/ros-2/python-rclpy","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/ros-2/python-rclpy.md","tags":[],"version":"current","frontMatter":{"title":"Writing a Python ROS 2 Node (RCLPy)","sidebar_label":"Python Node (RCLPy)"},"sidebar":"roboticsTextbookSidebar","previous":{"title":"Nodes, Topics, Services","permalink":"/docs/ros-2/understanding-nodes-topics-services"},"next":{"title":"URDF for Humanoids","permalink":"/docs/ros-2/urdf-for-humanoids"}},{"id":"ros-2/understanding-nodes-topics-services","title":"Understanding Nodes, Topics, and Services","description":"Welcome to the first lesson in our study of the Robotic Nervous System (ROS 2). In this section, we will explore the three fundamental concepts that form the backbone of all ROS 2 applications: Nodes, Topics, and Services.","source":"@site/docs/ros-2/understanding-nodes-topics-services.md","sourceDirName":"ros-2","slug":"/ros-2/understanding-nodes-topics-services","permalink":"/docs/ros-2/understanding-nodes-topics-services","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/ros-2/understanding-nodes-topics-services.md","tags":[],"version":"current","frontMatter":{"title":"Understanding Nodes, Topics, and Services","sidebar_label":"Nodes, Topics, Services"},"sidebar":"roboticsTextbookSidebar","next":{"title":"Python Node (RCLPy)","permalink":"/docs/ros-2/python-rclpy"}},{"id":"ros-2/urdf-for-humanoids","title":"Building URDF for Humanoid Models","description":"A crucial part of robotics simulation and visualization is having an accurate model of the robot itself. In the ROS ecosystem, the standard for describing a robot's physical structure is the Unified Robot Description Format (URDF).","source":"@site/docs/ros-2/urdf-for-humanoids.md","sourceDirName":"ros-2","slug":"/ros-2/urdf-for-humanoids","permalink":"/docs/ros-2/urdf-for-humanoids","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/ros-2/urdf-for-humanoids.md","tags":[],"version":"current","frontMatter":{"title":"Building URDF for Humanoid Models","sidebar_label":"URDF for Humanoids"},"sidebar":"roboticsTextbookSidebar","previous":{"title":"Python Node (RCLPy)","permalink":"/docs/ros-2/python-rclpy"},"next":{"title":"Setup Environments","permalink":"/docs/digital-twin/setup-environments"}},{"id":"vla/capstone-project","title":"Capstone Project - VLA-Powered Task Execution","description":"In this final lesson, we will bring together all the concepts from this textbook to create a complete Vision-Language-Action (VLA) system. Our goal is to build a simulated robot that can understand a spoken, high-level command and execute the corresponding physical task in a simulated environment.","source":"@site/docs/vla/capstone-project.md","sourceDirName":"vla","slug":"/vla/capstone-project","permalink":"/docs/vla/capstone-project","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/vla/capstone-project.md","tags":[],"version":"current","frontMatter":{"title":"Capstone Project - VLA-Powered Task Execution","sidebar_label":"Capstone Project"},"sidebar":"roboticsTextbookSidebar","previous":{"title":"Cognitive Planning with LLMs","permalink":"/docs/vla/llm-cognitive-planning"}},{"id":"vla/llm-cognitive-planning","title":"Cognitive Planning with LLMs","description":"Once a robot can understand spoken commands via a speech-to-text model like Whisper, the next challenge is to turn a high-level command like \"clean up the table\" into a concrete sequence of actions. This is the domain of task planning.","source":"@site/docs/vla/llm-cognitive-planning.md","sourceDirName":"vla","slug":"/vla/llm-cognitive-planning","permalink":"/docs/vla/llm-cognitive-planning","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/vla/llm-cognitive-planning.md","tags":[],"version":"current","frontMatter":{"title":"Cognitive Planning with LLMs","sidebar_label":"Cognitive Planning with LLMs"},"sidebar":"roboticsTextbookSidebar","previous":{"title":"Whisper Voice Commands","permalink":"/docs/vla/whisper-voice-commands"},"next":{"title":"Capstone Project","permalink":"/docs/vla/capstone-project"}},{"id":"vla/whisper-voice-commands","title":"Using Whisper for Voice Commands","description":"Welcome to our final chapter, where we bridge the gap between human language and robot action. Vision-Language-Action (VLA) models are at the forefront of AI, and the first step in building such a system is enabling the robot to understand spoken commands.","source":"@site/docs/vla/whisper-voice-commands.md","sourceDirName":"vla","slug":"/vla/whisper-voice-commands","permalink":"/docs/vla/whisper-voice-commands","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/vla/whisper-voice-commands.md","tags":[],"version":"current","frontMatter":{"title":"Using Whisper for Voice Commands","sidebar_label":"Whisper Voice Commands"},"sidebar":"roboticsTextbookSidebar","previous":{"title":"Nav2 Path Planning","permalink":"/docs/nvidia-isaac/nav2-path-planning"},"next":{"title":"Cognitive Planning with LLMs","permalink":"/docs/vla/llm-cognitive-planning"}}],"drafts":[],"sidebars":{"roboticsTextbookSidebar":[{"type":"category","label":"Chapter 1: The Robotic Nervous System (ROS 2)","items":[{"type":"doc","id":"ros-2/understanding-nodes-topics-services"},{"type":"doc","id":"ros-2/python-rclpy"},{"type":"doc","id":"ros-2/urdf-for-humanoids"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Chapter 2: The Digital Twin (Gazebo & Unity)","items":[{"type":"doc","id":"digital-twin/setup-environments"},{"type":"doc","id":"digital-twin/physics-simulation"},{"type":"doc","id":"digital-twin/simulating-sensors"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Chapter 3: The AI-Robot Brain (NVIDIA Isaac)","items":[{"type":"doc","id":"nvidia-isaac/intro-to-isaac-sim"},{"type":"doc","id":"nvidia-isaac/synthetic-data"},{"type":"doc","id":"nvidia-isaac/nav2-path-planning"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Chapter 4: Vision-Language-Action (VLA)","items":[{"type":"doc","id":"vla/whisper-voice-commands"},{"type":"doc","id":"vla/llm-cognitive-planning"},{"type":"doc","id":"vla/capstone-project"}],"collapsed":true,"collapsible":true}]}}]}},"docusaurus-plugin-content-blog":{"default":{"blogSidebarTitle":"Recent posts","blogPosts":[{"id":"welcome","metadata":{"permalink":"/blog/welcome","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2021-08-26-welcome/index.md","source":"@site/blog/2021-08-26-welcome/index.md","title":"Welcome","description":"Docusaurus blogging features are powered by the blog plugin.","date":"2021-08-26T00:00:00.000Z","tags":[{"inline":false,"label":"Facebook","permalink":"/blog/tags/facebook","description":"Facebook tag description"},{"inline":false,"label":"Hello","permalink":"/blog/tags/hello","description":"Hello tag description"},{"inline":false,"label":"Docusaurus","permalink":"/blog/tags/docusaurus","description":"Docusaurus tag description"}],"readingTime":0.56,"hasTruncateMarker":true,"authors":[{"name":"Sébastien Lorber","title":"Docusaurus maintainer","url":"https://sebastienlorber.com","page":{"permalink":"/blog/authors/all-sebastien-lorber-articles"},"socials":{"x":"https://x.com/sebastienlorber","linkedin":"https://www.linkedin.com/in/sebastienlorber/","github":"https://github.com/slorber","newsletter":"https://thisweekinreact.com"},"imageURL":"https://github.com/slorber.png","key":"slorber"},{"name":"Yangshun Tay","title":"Ex-Meta Staff Engineer, Co-founder GreatFrontEnd","url":"https://linkedin.com/in/yangshun","page":{"permalink":"/blog/authors/yangshun"},"socials":{"x":"https://x.com/yangshunz","linkedin":"https://www.linkedin.com/in/yangshun/","github":"https://github.com/yangshun","newsletter":"https://www.greatfrontend.com"},"imageURL":"https://github.com/yangshun.png","key":"yangshun"}],"frontMatter":{"slug":"welcome","title":"Welcome","authors":["slorber","yangshun"],"tags":["facebook","hello","docusaurus"]},"unlisted":false,"nextItem":{"title":"MDX Blog Post","permalink":"/blog/mdx-blog-post"}},"content":"[Docusaurus blogging features](https://docusaurus.io/docs/blog) are powered by the [blog plugin](https://docusaurus.io/docs/api/plugins/@docusaurus/plugin-content-blog).\r\n\r\nHere are a few tips you might find useful.\r\n\r\n<!-- truncate -->\r\n\r\nSimply add Markdown files (or folders) to the `blog` directory.\r\n\r\nRegular blog authors can be added to `authors.yml`.\r\n\r\nThe blog post date can be extracted from filenames, such as:\r\n\r\n- `2019-05-30-welcome.md`\r\n- `2019-05-30-welcome/index.md`\r\n\r\nA blog post folder can be convenient to co-locate blog post images:\r\n\r\n![Docusaurus Plushie](./docusaurus-plushie-banner.jpeg)\r\n\r\nThe blog supports tags as well!\r\n\r\n**And if you don't want a blog**: just delete this directory, and use `blog: false` in your Docusaurus config."},{"id":"mdx-blog-post","metadata":{"permalink":"/blog/mdx-blog-post","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2021-08-01-mdx-blog-post.mdx","source":"@site/blog/2021-08-01-mdx-blog-post.mdx","title":"MDX Blog Post","description":"Blog posts support Docusaurus Markdown features, such as MDX.","date":"2021-08-01T00:00:00.000Z","tags":[{"inline":false,"label":"Docusaurus","permalink":"/blog/tags/docusaurus","description":"Docusaurus tag description"}],"readingTime":0.27,"hasTruncateMarker":true,"authors":[{"name":"Sébastien Lorber","title":"Docusaurus maintainer","url":"https://sebastienlorber.com","page":{"permalink":"/blog/authors/all-sebastien-lorber-articles"},"socials":{"x":"https://x.com/sebastienlorber","linkedin":"https://www.linkedin.com/in/sebastienlorber/","github":"https://github.com/slorber","newsletter":"https://thisweekinreact.com"},"imageURL":"https://github.com/slorber.png","key":"slorber"}],"frontMatter":{"slug":"mdx-blog-post","title":"MDX Blog Post","authors":["slorber"],"tags":["docusaurus"]},"unlisted":false,"prevItem":{"title":"Welcome","permalink":"/blog/welcome"},"nextItem":{"title":"Long Blog Post","permalink":"/blog/long-blog-post"}},"content":"Blog posts support [Docusaurus Markdown features](https://docusaurus.io/docs/markdown-features), such as [MDX](https://mdxjs.com/).\r\n\r\n:::tip\r\n\r\nUse the power of React to create interactive blog posts.\r\n\r\n:::\r\n\r\n{/* truncate */}\r\n\r\nFor example, use JSX to create an interactive button:\r\n\r\n```js\r\n<button onClick={() => alert('button clicked!')}>Click me!</button>\r\n```\r\n\r\n<button onClick={() => alert('button clicked!')}>Click me!</button>"},{"id":"long-blog-post","metadata":{"permalink":"/blog/long-blog-post","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2019-05-29-long-blog-post.md","source":"@site/blog/2019-05-29-long-blog-post.md","title":"Long Blog Post","description":"This is the summary of a very long blog post,","date":"2019-05-29T00:00:00.000Z","tags":[{"inline":false,"label":"Hello","permalink":"/blog/tags/hello","description":"Hello tag description"},{"inline":false,"label":"Docusaurus","permalink":"/blog/tags/docusaurus","description":"Docusaurus tag description"}],"readingTime":2.04,"hasTruncateMarker":true,"authors":[{"name":"Yangshun Tay","title":"Ex-Meta Staff Engineer, Co-founder GreatFrontEnd","url":"https://linkedin.com/in/yangshun","page":{"permalink":"/blog/authors/yangshun"},"socials":{"x":"https://x.com/yangshunz","linkedin":"https://www.linkedin.com/in/yangshun/","github":"https://github.com/yangshun","newsletter":"https://www.greatfrontend.com"},"imageURL":"https://github.com/yangshun.png","key":"yangshun"}],"frontMatter":{"slug":"long-blog-post","title":"Long Blog Post","authors":"yangshun","tags":["hello","docusaurus"]},"unlisted":false,"prevItem":{"title":"MDX Blog Post","permalink":"/blog/mdx-blog-post"},"nextItem":{"title":"First Blog Post","permalink":"/blog/first-blog-post"}},"content":"This is the summary of a very long blog post,\r\n\r\nUse a `<!--` `truncate` `-->` comment to limit blog post size in the list view.\r\n\r\n<!-- truncate -->\r\n\r\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\r\n\r\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\r\n\r\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\r\n\r\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\r\n\r\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\r\n\r\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\r\n\r\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\r\n\r\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\r\n\r\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\r\n\r\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\r\n\r\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\r\n\r\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\r\n\r\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\r\n\r\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\r\n\r\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\r\n\r\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet"},{"id":"first-blog-post","metadata":{"permalink":"/blog/first-blog-post","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2019-05-28-first-blog-post.md","source":"@site/blog/2019-05-28-first-blog-post.md","title":"First Blog Post","description":"Lorem ipsum dolor sit amet...","date":"2019-05-28T00:00:00.000Z","tags":[{"inline":false,"label":"Hola","permalink":"/blog/tags/hola","description":"Hola tag description"},{"inline":false,"label":"Docusaurus","permalink":"/blog/tags/docusaurus","description":"Docusaurus tag description"}],"readingTime":0.13,"hasTruncateMarker":true,"authors":[{"name":"Sébastien Lorber","title":"Docusaurus maintainer","url":"https://sebastienlorber.com","page":{"permalink":"/blog/authors/all-sebastien-lorber-articles"},"socials":{"x":"https://x.com/sebastienlorber","linkedin":"https://www.linkedin.com/in/sebastienlorber/","github":"https://github.com/slorber","newsletter":"https://thisweekinreact.com"},"imageURL":"https://github.com/slorber.png","key":"slorber"},{"name":"Yangshun Tay","title":"Ex-Meta Staff Engineer, Co-founder GreatFrontEnd","url":"https://linkedin.com/in/yangshun","page":{"permalink":"/blog/authors/yangshun"},"socials":{"x":"https://x.com/yangshunz","linkedin":"https://www.linkedin.com/in/yangshun/","github":"https://github.com/yangshun","newsletter":"https://www.greatfrontend.com"},"imageURL":"https://github.com/yangshun.png","key":"yangshun"}],"frontMatter":{"slug":"first-blog-post","title":"First Blog Post","authors":["slorber","yangshun"],"tags":["hola","docusaurus"]},"unlisted":false,"prevItem":{"title":"Long Blog Post","permalink":"/blog/long-blog-post"}},"content":"Lorem ipsum dolor sit amet...\r\n\r\n<!-- truncate -->\r\n\r\n...consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet"}],"blogListPaginated":[{"items":["welcome","mdx-blog-post","long-blog-post","first-blog-post"],"metadata":{"permalink":"/blog","page":1,"postsPerPage":10,"totalPages":1,"totalCount":4,"blogDescription":"Blog","blogTitle":"Blog"}}],"blogTags":{"/blog/tags/facebook":{"inline":false,"label":"Facebook","permalink":"/blog/tags/facebook","description":"Facebook tag description","items":["welcome"],"pages":[{"items":["welcome"],"metadata":{"permalink":"/blog/tags/facebook","page":1,"postsPerPage":10,"totalPages":1,"totalCount":1,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/blog/tags/hello":{"inline":false,"label":"Hello","permalink":"/blog/tags/hello","description":"Hello tag description","items":["welcome","long-blog-post"],"pages":[{"items":["welcome","long-blog-post"],"metadata":{"permalink":"/blog/tags/hello","page":1,"postsPerPage":10,"totalPages":1,"totalCount":2,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/blog/tags/docusaurus":{"inline":false,"label":"Docusaurus","permalink":"/blog/tags/docusaurus","description":"Docusaurus tag description","items":["welcome","mdx-blog-post","long-blog-post","first-blog-post"],"pages":[{"items":["welcome","mdx-blog-post","long-blog-post","first-blog-post"],"metadata":{"permalink":"/blog/tags/docusaurus","page":1,"postsPerPage":10,"totalPages":1,"totalCount":4,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/blog/tags/hola":{"inline":false,"label":"Hola","permalink":"/blog/tags/hola","description":"Hola tag description","items":["first-blog-post"],"pages":[{"items":["first-blog-post"],"metadata":{"permalink":"/blog/tags/hola","page":1,"postsPerPage":10,"totalPages":1,"totalCount":1,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false}},"blogTagsListPath":"/blog/tags","authorsMap":{"yangshun":{"name":"Yangshun Tay","title":"Ex-Meta Staff Engineer, Co-founder GreatFrontEnd","url":"https://linkedin.com/in/yangshun","page":{"permalink":"/blog/authors/yangshun"},"socials":{"x":"https://x.com/yangshunz","linkedin":"https://www.linkedin.com/in/yangshun/","github":"https://github.com/yangshun","newsletter":"https://www.greatfrontend.com"},"imageURL":"https://github.com/yangshun.png","key":"yangshun"},"slorber":{"name":"Sébastien Lorber","title":"Docusaurus maintainer","url":"https://sebastienlorber.com","page":{"permalink":"/blog/authors/all-sebastien-lorber-articles"},"socials":{"x":"https://x.com/sebastienlorber","linkedin":"https://www.linkedin.com/in/sebastienlorber/","github":"https://github.com/slorber","newsletter":"https://thisweekinreact.com"},"imageURL":"https://github.com/slorber.png","key":"slorber"}}}},"docusaurus-plugin-content-pages":{"default":[{"type":"jsx","permalink":"/","source":"@site/src/pages/index.tsx"},{"type":"mdx","permalink":"/markdown-page","source":"@site/src/pages/markdown-page.md","title":"Markdown page example","description":"You don't need React to write simple standalone pages.","frontMatter":{"title":"Markdown page example"},"unlisted":false}]},"docusaurus-plugin-debug":{},"docusaurus-plugin-svgr":{},"docusaurus-theme-classic":{},"docusaurus-bootstrap-plugin":{},"docusaurus-mdx-fallback-plugin":{}}}